import pandas as pd
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import os


########################################################
# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'  # macOSì˜ ê²½ìš°
plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

########################################################

# ë‘ ë²ˆì§¸ ì…€ - ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬

# ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def convert_to_numeric(x):
    if pd.isna(x):
        return np.nan
    if isinstance(x, str):
        x = x.replace(',', '').strip()
        if '%' in x:
            return float(x.replace('%', '')) / 100
    return pd.to_numeric(x, errors='coerce')

def load_and_preprocess_data():
    try:
        # ë°ì´í„° í´ë” ê²½ë¡œ ì„¤ì •
        data_folder = os.path.dirname(os.path.abspath(__file__))
        
        # ì…ì°°ì •ë³´ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        bid_files = [os.path.join(data_folder, f'bid_info_{i}.xlsx') for i in range(1, 6)]
        existing_bid_files = [f for f in bid_files if os.path.exists(f)]
        
        if not existing_bid_files:
            st.error("ì…ì°°ì •ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        # ì…ì°°ì •ë³´ íŒŒì¼ ì½ê¸°
        bid_dfs = []
        for file in existing_bid_files:
            try:
                df = pd.read_excel(file, header=1)
                if not df.empty:
                    bid_dfs.append(df)
            except Exception as e:
                continue
        
        if not bid_dfs:
            st.error("ì½ì„ ìˆ˜ ìˆëŠ” ì…ì°°ì •ë³´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        # ì…ì°°ì •ë³´ ë³‘í•© ë° ì¤‘ë³µ ì œê±°
        merged_bid = pd.concat(bid_dfs, axis=0, ignore_index=True)
        
        # ì¤‘ë³µ ì œê±° ì „ ë°ì´í„° ìˆ˜ ì €ì¥
        before_drop_duplicates = len(merged_bid)
        
        # ê³µê³ ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±° (ìµœì‹  ë°ì´í„° ìœ ì§€)
        merged_bid = merged_bid.sort_values('ê°œì°°ì¼', ascending=False)  # ìµœì‹  ë°ì´í„°ê°€ ìœ„ë¡œ ì˜¤ë„ë¡ ì •ë ¬
        merged_bid = merged_bid.drop_duplicates(subset=['ê³µê³ ë²ˆí˜¸'], keep='first')
        
        # ì¤‘ë³µ ì œê±° í›„ ë°ì´í„° ìˆ˜ ê³„ì‚°
        after_drop_duplicates = len(merged_bid)
        removed_duplicates = before_drop_duplicates - after_drop_duplicates
        
        if removed_duplicates > 0:
            st.info(f"ì¤‘ë³µëœ ê³µê³ ë²ˆí˜¸ {removed_duplicates}ê°œê°€ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤. (ì „ì²´: {before_drop_duplicates}ê°œ â†’ {after_drop_duplicates}ê°œ)")
        
        try:
            # ë‚™ì°°ì •ë³´ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ì˜ë¬¸ íŒŒì¼ëª… ì‚¬ìš©)
            award_files = [os.path.join(data_folder, f'award_info_{i}.xlsx') for i in range(1, 6)]
            existing_award_files = [f for f in award_files if os.path.exists(f)]
            
            award_dfs = []
            if existing_award_files:  # ë‚™ì°°ì •ë³´ íŒŒì¼ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì²˜ë¦¬
                for file in existing_award_files:
                    try:
                        df = pd.read_excel(file, header=1)
                        if not df.empty:
                            award_dfs.append(df)
                    except Exception as e:
                        st.warning(f"ë‚™ì°°ì •ë³´ íŒŒì¼ '{file}' ì½ê¸° ì‹¤íŒ¨: {str(e)}")
                        continue
            
            if award_dfs:  # ë‚™ì°°ì •ë³´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ë³‘í•©
                merged_award = pd.concat(award_dfs, axis=0, ignore_index=True)
                
                # ë‚™ì°°ì •ë³´ë„ ì¤‘ë³µ ì œê±° (ìµœì‹  ë°ì´í„° ìœ ì§€)
                before_award_duplicates = len(merged_award)
                merged_award = merged_award.drop_duplicates(subset=['ê³µê³ ë²ˆí˜¸'], keep='first')
                after_award_duplicates = len(merged_award)
                removed_award_duplicates = before_award_duplicates - after_award_duplicates
                
                if removed_award_duplicates > 0:
                    st.info(f"ë‚™ì°°ì •ë³´ì—ì„œ ì¤‘ë³µëœ ê³µê³ ë²ˆí˜¸ {removed_award_duplicates}ê°œê°€ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                # ì…ì°°ì •ë³´ì™€ ë‚™ì°°ì •ë³´ ë³‘í•©
                columns_to_use = [col for col in merged_award.columns if col not in merged_bid.columns or col == 'ê³µê³ ë²ˆí˜¸']
                merged_data = pd.merge(
                    merged_bid,
                    merged_award[columns_to_use],
                    on='ê³µê³ ë²ˆí˜¸',
                    how='left'
                )
            else:
                merged_data = merged_bid
                st.info("ë‚™ì°°ì •ë³´ íŒŒì¼ì´ ì—†ê±°ë‚˜ ì½ì„ ìˆ˜ ì—†ì–´ ì…ì°°ì •ë³´ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        except Exception as e:
            st.warning(f"ë‚™ì°°ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            merged_data = merged_bid
        
        # ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•  ì—´ ëª©ë¡
        numeric_columns = ['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€', '1ìˆœìœ„ì‚¬ì •ë¥ ']
        
        # ìˆ«ìí˜• ë³€í™˜
        # ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•  ì—´ ëª©ë¡
        numeric_columns = ['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€', '1ìˆœìœ„ì‚¬ì •ë¥ ']

        # ìˆ«ìí˜• ë³€í™˜
        for col in numeric_columns:
            if col in merged_data.columns:
                merged_data[col] = merged_data[col].apply(convert_to_numeric)
        
        # 'ë²ˆí˜¸' ì—´ ì‚­ì œ
        if 'ë²ˆí˜¸' in merged_data.columns:
            merged_data = merged_data.drop('ë²ˆí˜¸', axis=1)
        
        return merged_data
        
    except Exception as e:
        st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return pd.DataFrame()

# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì‹¤í–‰
processed_data = load_and_preprocess_data()

########################################################
# ì›¹ì— ë°ì´í„° í”„ë ˆì„ í‘œì‹œ
st.title('ë‚˜ë¼ì¥í„° íˆ¬ì°°ì„ ìœ„í•œ ì‚¬ì •ë¥  êµ¬í•˜ê¸°')

# ë°ì´í„° í”„ë ˆì„ í‘œì‹œ    
st.header("1. 2021ë…„ 01ì›” ì´í›„ ë‚˜ë¼ì¥í„° ì…ì°° ë° ë‚™ì°° ì •ë³´", divider=True)

st.dataframe(processed_data, use_container_width=False)
# ë°ì´í„° ì •ë³´ í‘œì‹œ
st.caption(f"ì „ì²´ {len(processed_data):,}ê°œì˜ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

########################################################
# íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ë“¤ì„ ë‚˜ëˆ„ì–´ ë°°ì¹˜
col1, col2 = st.columns(2)

with col1:
    st.subheader("ìƒˆë¡œìš´ ì…ì°° ë°ì´í„° ì—…ë¡œë“œ")
    bid_file = st.file_uploader("ì…ì°° ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['xlsx', 'xls'], key='bid_upload')
    
    if bid_file is not None:
        try:
            # ê¸°ì¡´ì˜ ì…ì°° ë°ì´í„° ì—…ë¡œë“œ ë¡œì§
            new_data = pd.read_excel(bid_file, header=1)
            existing_columns = processed_data.columns
            new_data = new_data[existing_columns.intersection(new_data.columns)]
            
            # # ë°ì´í„° í™•ì¸ì„ ìœ„í•œ ì •ë³´ ì¶œë ¥
            # st.write("ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì—´:", new_data.columns.tolist())
            
            required_columns = ['ê³µê³ ë²ˆí˜¸'] + ['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€']
            missing_columns = set(required_columns) - set(new_data.columns)
            
            if missing_columns:
                st.error(f"í•„ìˆ˜ ì—´ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_columns)}")
            else:
                # ì—…ë°ì´íŠ¸ ì „ ë°ì´í„° ìƒíƒœ í™•ì¸
                before_count = len(processed_data)
                before_empty = processed_data['1ìˆœìœ„ì‚¬ì •ë¥ '].isna().sum()
                
                # ìˆ«ìí˜• ë°ì´í„° ë³€í™˜
                numeric_columns = ['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€']
                for col in numeric_columns:
                    if col in new_data.columns:
                        new_data[col] = new_data[col].apply(convert_to_numeric)
                
                # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•© (ì¤‘ë³µ ì œê±°)
                processed_data = pd.concat([processed_data, new_data], axis=0)
                processed_data = processed_data.drop_duplicates(subset=['ê³µê³ ë²ˆí˜¸'], keep='first')
                
                # ì—…ë°ì´íŠ¸ í›„ ë°ì´í„° ìƒíƒœ í™•ì¸
                after_count = len(processed_data)
                after_empty = processed_data['1ìˆœìœ„ì‚¬ì •ë¥ '].isna().sum()
                update_count = after_count - before_count
                
                st.success(f"""
                ì…ì°° ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.
                - ì¶”ê°€ëœ ìƒˆë¡œìš´ í–‰ ìˆ˜: {update_count}ê°œ
                - ì—…ë°ì´íŠ¸ ì „ ì „ì²´ í–‰ ìˆ˜: {before_count}ê°œ
                - ì—…ë°ì´íŠ¸ í›„ ì „ì²´ í–‰ ìˆ˜: {after_count}ê°œ
                - ì—…ë°ì´íŠ¸ ì „ ë¹ˆ ê°’: {before_empty}ê°œ
                - ì—…ë°ì´íŠ¸ í›„ ë¹ˆ ê°’: {after_empty}ê°œ
                """)
                
        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.write("ì˜¤ë¥˜ ìƒì„¸:", str(e))

with col2:
    st.subheader("ìƒˆë¡œìš´ ë‚™ì°° ë°ì´í„° ì—…ë¡œë“œ")
    award_file = st.file_uploader("ë‚™ì°° ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['xlsx', 'xls'], key='award_upload')
    
    if award_file is not None:
        try:
            # ìƒˆë¡œìš´ ë‚™ì°° ë°ì´í„° ì½ê¸° (header=1 ì„¤ì •)
            new_award_data = pd.read_excel(award_file, header=1)
            
            # # ë°ì´í„° í™•ì¸ì„ ìœ„í•œ ì •ë³´ ì¶œë ¥
            # st.write("ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì—´:", new_award_data.columns.tolist())
            
            # í•„ìˆ˜ ì—´ í™•ì¸
            required_columns = ['ê³µê³ ë²ˆí˜¸', '1ìˆœìœ„ì‚¬ì •ë¥ ']
            missing_columns = set(required_columns) - set(new_award_data.columns)
            
            if missing_columns:
                st.error(f"í•„ìˆ˜ ì—´ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_columns)}")
            else:
                # ìˆ«ìí˜• ë°ì´í„° ë³€í™˜
                if '1ìˆœìœ„ì‚¬ì •ë¥ ' in new_award_data.columns:
                    new_award_data['1ìˆœìœ„ì‚¬ì •ë¥ '] = new_award_data['1ìˆœìœ„ì‚¬ì •ë¥ '].apply(convert_to_numeric)
                
                # ì—…ë°ì´íŠ¸ ì „ ë°ì´í„° ìƒíƒœ í™•ì¸
                before_empty = processed_data['1ìˆœìœ„ì‚¬ì •ë¥ '].isna().sum()
                
                # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆë¡œìš´ ë°ì´í„°ì˜ ê³µê³ ë²ˆí˜¸ ë§¤ì¹­
                update_count = 0
                for idx, row in new_award_data.iterrows():
                    mask = (processed_data['ê³µê³ ë²ˆí˜¸'] == row['ê³µê³ ë²ˆí˜¸']) & \
                          (pd.isna(processed_data['1ìˆœìœ„ì‚¬ì •ë¥ ']))
                    
                    if mask.any():
                        # ë¹ˆ ê°’ë§Œ ì—…ë°ì´íŠ¸
                        for col in new_award_data.columns:
                            if col in processed_data.columns and col != 'ê³µê³ ë²ˆí˜¸':
                                processed_data.loc[mask, col] = row[col]
                        update_count += 1
                
                # ì—…ë°ì´íŠ¸ í›„ ë°ì´í„° ìƒíƒœ í™•ì¸
                after_empty = processed_data['1ìˆœìœ„ì‚¬ì •ë¥ '].isna().sum()
                
                st.success(f"""
                ë‚™ì°° ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.
                - ì—…ë°ì´íŠ¸ëœ í–‰ ìˆ˜: {update_count}ê°œ
                - ì—…ë°ì´íŠ¸ ì „ ë¹ˆ ê°’: {before_empty}ê°œ
                - ì—…ë°ì´íŠ¸ í›„ ë¹ˆ ê°’: {after_empty}ê°œ
                """)
                
        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.write("ì˜¤ë¥˜ ìƒì„¸:", str(e))

########################################################
# ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
st.text("\n=== ë°ì´í„° ë‹¤ìš´ë¡œë“œ ===")
# BytesIOë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ì— ì—‘ì…€ íŒŒì¼ ìƒì„±
from io import BytesIO
import xlsxwriter

def to_excel(df):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, sheet_name='Sheet1', index=False)
        # ìë™ ì—´ ë„ˆë¹„ ì¡°ì •
        worksheet = writer.sheets['Sheet1']
        for i, col in enumerate(df.columns):
            column_len = max(df[col].astype(str).apply(len).max(), len(col)) + 2
            worksheet.set_column(i, i, column_len)
    output.seek(0)
    return output

# ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„±
excel_file = to_excel(processed_data)
st.download_button(
    label="ğŸ“¥ ì—…ë°ì´íŠ¸ëœ ë°ì´í„° ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
    data=excel_file,
    file_name='ë‚˜ë¼ì¥í„°_ì…ì°°ì •ë³´.xlsx',
    mime='application/vnd.ms-excel'
)

# ë°ì´í„° ì •ë³´ í‘œì‹œ
st.caption(f"ì „ì²´ {len(processed_data):,}ê°œì˜ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

########################################################
st.header("2. ê¸°ì´ˆê¸ˆì•¡ êµ¬ê°„ë³„ 1ìˆœìœ„ì‚¬ì •ë¥  ë¶„í¬", divider=True)

# ìœ íš¨í•œ ë°ì´í„°ë§Œ í•„í„°ë§
valid_data = processed_data.dropna(subset=['ê¸°ì´ˆê¸ˆì•¡', '1ìˆœìœ„ì‚¬ì •ë¥ ']).copy()

if len(valid_data) > 0:
    try:
        # ë°ì´í„° ì „ì²˜ë¦¬ ì „ ìƒíƒœ ì¶œë ¥
        st.text(f"ì „ì²˜ë¦¬ ì „ ë°ì´í„° ìˆ˜: {len(valid_data):,}ê°œ")
        
        # ì´ìƒì¹˜ ì œê±° ê¸°ì¤€ ì™„í™” (96%~104% ë²”ìœ„)
        valid_data = valid_data[
            (valid_data['1ìˆœìœ„ì‚¬ì •ë¥ '] >= 96.0) & 
            (valid_data['1ìˆœìœ„ì‚¬ì •ë¥ '] <= 104.0)
        ]
        
        st.text(f"ì „ì²˜ë¦¬ í›„ ë°ì´í„° ìˆ˜: {len(valid_data):,}ê°œ")
        
        if len(valid_data) > 0:
            # ê¸°ì´ˆê¸ˆì•¡ êµ¬ê°„ ìƒì„± (ìµœì†Œ 10ê°œ êµ¬ê°„ ë³´ì¥)
            bins = max(10, min(50, len(valid_data) // 20))
            valid_data['ê¸°ì´ˆê¸ˆì•¡_êµ¬ê°„'] = pd.qcut(valid_data['ê¸°ì´ˆê¸ˆì•¡'], q=bins, duplicates='drop')
            
            # êµ¬ê°„ë³„ í†µê³„ ê³„ì‚°
            stats = valid_data.groupby('ê¸°ì´ˆê¸ˆì•¡_êµ¬ê°„').agg({
                '1ìˆœìœ„ì‚¬ì •ë¥ ': ['mean', 'min', 'max', 'count'],
                'ê¸°ì´ˆê¸ˆì•¡': 'mean'
            }).reset_index()
            
            # ì»¬ëŸ¼ëª… ì •ë¦¬
            stats.columns = ['ê¸°ì´ˆê¸ˆì•¡_êµ¬ê°„', 'í‰ê· ì‚¬ì •ë¥ ', 'ìµœì €ì‚¬ì •ë¥ ', 'ìµœê³ ì‚¬ì •ë¥ ', 'ê±´ìˆ˜', 'ê¸°ì´ˆê¸ˆì•¡']
            
            # íˆìŠ¤í† ê·¸ë¨ ìƒì„±
            fig, ax = plt.subplots(figsize=(15, 6))
            
            # íˆìŠ¤í† ê·¸ë¨ ê·¸ë¦¬ê¸°
            sns.histplot(data=valid_data, 
                        x='1ìˆœìœ„ì‚¬ì •ë¥ ',
                        bins=50,  # êµ¬ê°„ ìˆ˜ ì¡°ì •
                        kde=True)  # ë°€ë„ ê³¡ì„  ì¶”ê°€
            
            # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ë§
            plt.title('1ìˆœìœ„ì‚¬ì •ë¥  ë¶„í¬', pad=20)
            plt.xlabel('1ìˆœìœ„ì‚¬ì •ë¥  (%)', labelpad=10)
            plt.ylabel('ë¹ˆë„ìˆ˜', labelpad=10)
            
            # ê·¸ë¦¬ë“œ ì¶”ê°€
            plt.grid(True, alpha=0.3)
            
            # Streamlitì— ê·¸ë˜í”„ í‘œì‹œ
            st.pyplot(fig)
            
            # í†µê³„ ì •ë³´ í‘œì‹œ
            st.subheader('1ìˆœìœ„ì‚¬ì •ë¥  í†µê³„')
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("í‰ê·  ê¸°ì´ˆê¸ˆì•¡", f"{format(int(valid_data['ê¸°ì´ˆê¸ˆì•¡'].mean()), ',')}")
            with col2:
                st.metric("ìµœê³  ì‚¬ì •ë¥ ", f"{valid_data['1ìˆœìœ„ì‚¬ì •ë¥ '].max():.2f}%")
            with col3:
                st.metric("ìµœì € ì‚¬ì •ë¥ ", f"{valid_data['1ìˆœìœ„ì‚¬ì •ë¥ '].min():.2f}%")
                
            # ë°ì´í„° ìˆ˜ í‘œì‹œ
            st.caption(f"ë¶„ì„ì— ì‚¬ìš©ëœ ë°ì´í„° ìˆ˜: {len(valid_data):,}ê°œ")
            
        else:
            st.warning("ìœ íš¨í•œ ë²”ìœ„(96%~104%) ë‚´ì˜ ì‚¬ì •ë¥  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        st.error(f"ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
else:
    st.warning("ë¶„ì„í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

########################################################


# ì„¸ ë²ˆì§¸ ì…€ - ì˜ˆì¸¡ ëª¨ë¸ í´ë˜ìŠ¤
class BidPricePredictor:
    def __init__(self, data):
        # ê²°ì¸¡ì¹˜ê°€ ì—†ëŠ” ë°ì´í„°ë§Œ ì„ íƒ
        required_columns = ['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€',  '1ìˆœìœ„ì‚¬ì •ë¥ ']
        self.data = data.dropna(subset=required_columns).copy()
        self.model = None
        self.scaler = StandardScaler()
        
        st.text("=== ëª¨ë¸ ì´ˆê¸°í™” ===")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ì „ì²´ ë°ì´í„° ìˆ˜", f"{len(data):,}ê°œ")
        with col2:
            st.metric("í•™ìŠµ ê°€ëŠ¥í•œ ë°ì´í„° ìˆ˜", f"{len(self.data):,}ê°œ")
    
    def prepare_data(self):
        features = ['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€']
        target = '1ìˆœìœ„ì‚¬ì •ë¥ '
        
        # ë°ì´í„° ì „ì²˜ë¦¬ ì „ ìƒíƒœ ì¶œë ¥
        st.text(f"ì „ì²˜ë¦¬ ì „ ë°ì´í„° ìˆ˜: {len(self.data):,}ê°œ")
        
        # ì´ìƒì¹˜ ì œê±° ê¸°ì¤€ ì™„í™” (50%~150% ë²”ìœ„)
        clean_data = self.data[
            (self.data[target] >= 50.0) & 
            (self.data[target] <= 150.0)
        ]
        
        st.text(f"ì „ì²˜ë¦¬ í›„ ë°ì´í„° ìˆ˜: {len(clean_data):,}ê°œ")
        
        if len(clean_data) == 0:
            st.error("ì „ì²˜ë¦¬ í›„ ë‚¨ì€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            raise ValueError("ì „ì²˜ë¦¬ í›„ ë‚¨ì€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        X = clean_data[features]
        y = clean_data[target]
        
        # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
        X_scaled = self.scaler.fit_transform(X)
        
        return X_scaled, y, clean_data

    def train_model(self):
        try:
            X_scaled, y, clean_data = self.prepare_data()
            
            # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(
                X_scaled, y, test_size=0.2, random_state=42
            )
            
            # ëª¨ë¸ í•™ìŠµ
            self.model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42
            )
            self.model.fit(X_train, y_train)
            
            # ì„±ëŠ¥ í‰ê°€
            train_score = self.model.score(X_train, y_train)
            test_score = self.model.score(X_test, y_test)
            
            # ì„±ëŠ¥ ì§€í‘œ í‘œì‹œ
            st.text("\n=== ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ===")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("í•™ìŠµ ë°ì´í„° RÂ² ì ìˆ˜", f"{train_score:.4f}")
            with col2:
                st.metric("í…ŒìŠ¤íŠ¸ ë°ì´í„° RÂ² ì ìˆ˜", f"{test_score:.4f}")
            
            # íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”
            feature_importance = pd.DataFrame({
                'íŠ¹ì„±': ['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€'],
                'ì¤‘ìš”ë„': self.model.feature_importances_
            })
            feature_importance = feature_importance.sort_values('ì¤‘ìš”ë„', ascending=True)
            
            fig, ax = plt.subplots(figsize=(10, 5))
            bars = ax.barh(feature_importance['íŠ¹ì„±'], feature_importance['ì¤‘ìš”ë„'])
            
            # ë§‰ëŒ€ ëì— ê°’ í‘œì‹œ
            for bar in bars:
                width = bar.get_width()
                ax.text(width, bar.get_y() + bar.get_height()/2, 
                       f'{width:.4f}', 
                       ha='left', va='center', fontsize=10)
            
            plt.title('íŠ¹ì„± ì¤‘ìš”ë„')
            plt.xlabel('ì¤‘ìš”ë„')
            st.pyplot(fig)
            
            return self.model, clean_data
            
        except Exception as e:
            st.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return None, None
    
    def predict_rate(self, new_data):
        if self.model is None:
            st.error("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € train_model()ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
            return None
        
        try:
            # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ ì ìš©
            scaled_data = self.scaler.transform(new_data)
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            predicted = self.model.predict(scaled_data)[0]
            
            return predicted
            
        except Exception as e:
            st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return None

########################################################
########################################################
st.header("3. ì‚¬ì •ë¥  ì˜ˆì¸¡ ëª¨ë¸", divider=True)

# ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©í•  ì™„ì „í•œ ë°ì´í„° í™•ì¸
complete_data = processed_data.dropna(subset=['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€', '1ìˆœìœ„ì‚¬ì •ë¥ '])

# ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë²„íŠ¼
if st.button("ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ì‹œì‘", type="primary"):
    with st.spinner("ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ì¤‘..."):
        try:
            # ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
            predictor = BidPricePredictor(processed_data)
            model = predictor.train_model()
            
            # í•™ìŠµëœ ëª¨ë¸ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state['predictor'] = predictor
            st.session_state['model_trained'] = True
            
            st.success("ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ìƒˆë¡œìš´ ì…ì°°ê±´ì˜ ì‚¬ì •ë¥ ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            st.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.session_state['model_trained'] = False

# ì˜ˆì¸¡ ì‹¤í–‰ (ëª¨ë¸ì´ í•™ìŠµëœ ê²½ìš°ì—ë§Œ)
if st.session_state.get('model_trained', False):
    # ì˜ˆì¸¡í•  ë°ì´í„° ì„ íƒ (1ìˆœìœ„ì‚¬ì •ë¥ ì´ ì—†ëŠ” ë°ì´í„° ì¤‘ ë‹¤ë¥¸ í•„ìˆ˜ ì»¬ëŸ¼ì€ ìˆëŠ” ë°ì´í„°)
    prediction_candidates = processed_data[pd.isna(processed_data['1ìˆœìœ„ì‚¬ì •ë¥ '])].copy()
    prediction_data = prediction_candidates.dropna(subset=['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€'])
    
    if len(prediction_data) > 0:
        st.subheader("ìƒˆë¡œìš´ ì…ì°°ê±´ ì‚¬ì •ë¥  ì˜ˆì¸¡ ê²°ê³¼")
        
        # ì˜ˆì¸¡ ì‹¤í–‰
        features = ['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€']
        predictions = []
        
        predictor = st.session_state['predictor']
        for idx, row in prediction_data[features].iterrows():
            try:
                predicted_rate = predictor.predict_rate(row.values.reshape(1, -1))
                predictions.append(predicted_rate)
            except:
                predictions.append(np.nan)
        
        # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
        prediction_data['1ìˆœìœ„ì‚¬ì •ë¥ (ì˜ˆì¸¡ê°’)'] = predictions
        
        # í‘œì‹œí•  ì—´ ì„ íƒ ë° ì •ë ¬
        display_columns = [
            'ê³µê³ ë²ˆí˜¸',
            'ê³µì‚¬ëª…',
            'ê°œì°°ì¼',
            'ìˆ˜ìš”ê¸°ê´€',
            'ê°œì°°ì¼ì‹œ',
            'ê¸°ì´ˆê¸ˆì•¡',
            'ì¶”ì •ê°€ê²©',
            'íˆ¬ì°°ë¥ ',
            'Aê°’',
            'ìˆœê³µì‚¬ì›ê°€',
            '1ìˆœìœ„ì‚¬ì •ë¥ (ì˜ˆì¸¡ê°’)'
        ]
        
        # ì‹¤ì œ í‘œì‹œí•  ì—´ì€ ë°ì´í„°í”„ë ˆì„ì— ì¡´ì¬í•˜ëŠ” ì—´ë§Œ ì„ íƒ
        display_columns = [col for col in display_columns if col in prediction_data.columns]
        
        # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
        st.dataframe(
            prediction_data[display_columns].style.format({
                'ê³µê³ ë²ˆí˜¸': '{}',  # ë¬¸ìì—´ ê·¸ëŒ€ë¡œ í‘œì‹œ
                'ê³µì‚¬ëª…': '{}',  # ë¬¸ìì—´ ê·¸ëŒ€ë¡œ í‘œì‹œ
                'ê°œì°°ì¼': '{}',  # ë‚ ì§œ/ì‹œê°„ ê·¸ëŒ€ë¡œ í‘œì‹œ
                'ìˆ˜ìš”ê¸°ê´€': '{}', # ë¬¸ìì—´ ê·¸ëŒ€ë¡œ í‘œì‹œ
                'ê¸°ì´ˆê¸ˆì•¡': '{:,.0f}',
                'ì¶”ì •ê°€ê²©': '{:,.0f}',
                'íˆ¬ì°°ë¥ ': '{:.4f}',
                'Aê°’': '{:.4f}',
                'ìˆœê³µì‚¬ì›ê°€': '{:,.0f}',
                '1ìˆœìœ„ì‚¬ì •ë¥ (ì˜ˆì¸¡ê°’)': '{:.4f}'
            }),
            use_container_width=True
        )
        
        # ì˜ˆì¸¡ í†µê³„ ì •ë³´
        valid_predictions = prediction_data['1ìˆœìœ„ì‚¬ì •ë¥ (ì˜ˆì¸¡ê°’)'].dropna()
        if len(valid_predictions) > 0:
            st.text("\n=== ì˜ˆì¸¡ëœ ì‚¬ì •ë¥  í†µê³„ ===")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("í‰ê·  ì‚¬ì •ë¥ ", f"{valid_predictions.mean():.4f}%")
            with col2:
                st.metric("ìµœì†Œ ì‚¬ì •ë¥ ", f"{valid_predictions.min():.4f}%")
            with col3:
                st.metric("ìµœëŒ€ ì‚¬ì •ë¥ ", f"{valid_predictions.max():.4f}%")
        
        st.caption(f"ì˜ˆì¸¡ëœ ì…ì°°ê±´ ìˆ˜: {len(valid_predictions):,}ê°œ")
    else:
        st.info("ì˜ˆì¸¡í•  ìƒˆë¡œìš´ ì…ì°°ê±´ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.info("ë¨¼ì € ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
