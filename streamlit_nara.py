import pandas as pd
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import platform
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import os
import requests
import seaborn as sns
from io import BytesIO
import xlsxwriter
from scipy.stats import norm
from scipy.stats import gaussian_kde

# ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ í•¨ìˆ˜
def categorize_client(client):
    """ë°œì£¼ì²˜ë¥¼ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ëŠ” í•¨ìˆ˜"""
    if pd.isna(client):
        return 'ê¸°íƒ€'
        
    client = str(client).strip()
    
    # êµ°ì‚¬ê¸°ê´€ (ê°€ì¥ ë¨¼ì € ê²€ì‚¬)
    if any(word in client for word in [
        'êµ°', 'ê³µêµ°', 'í•´êµ°', 'ìœ¡êµ°', 'êµ­ë°©', 'êµ­êµ°', 'êµ°ì‚¬', 'êµ°ë‹¨', 
        'ì‚¬ë ¹ë¶€', 'êµ°ìˆ˜', 'êµ°ë¹„', 'êµ°ì‹œì„¤', 'êµ°ì‚¬ì‹œì„¤', 'êµ°ë¶€ëŒ€'
    ]):
        return 'êµ°ì‚¬ê¸°ê´€'
    
    # ì„œìš¸íŠ¹ë³„ì‹œêµìœ¡ì²­ ê´€ë ¨ ê¸°ê´€
    if 'ì„œìš¸íŠ¹ë³„ì‹œêµìœ¡ì²­' in client:
        return 'ì„œìš¸íŠ¹ë³„ì‹œêµìœ¡ì²­'
    
    # ì„œìš¸íŠ¹ë³„ì‹œ ê´€ë ¨ ê¸°ê´€
    if 'ì„œìš¸íŠ¹ë³„ì‹œ' in client or 'ì„œìš¸ì‹œ' in client:
        return 'ì„œìš¸íŠ¹ë³„ì‹œ'
    
    # êµìœ¡ê¸°ê´€ ë¶„ë¥˜
    if any(word in client for word in ['êµìœ¡ì²­', 'êµìœ¡ì§€ì›ì²­']):
        return 'êµìœ¡ì²­'
    elif any(word in client for word in ['ê³ ë“±í•™êµ', 'ì¤‘í•™êµ', 'ì´ˆë“±í•™êµ', 'í•™êµ', 'ëŒ€í•™êµ']):
        return 'í•™êµ'
    
    # ì¤‘ì•™í–‰ì •ê¸°ê´€ ì„¸ë¶„í™”
    if 'êµ­í† êµí†µë¶€' in client or 'êµ­í† ë¶€' in client:
        return 'êµ­í† êµí†µë¶€'
    elif 'ì¡°ë‹¬ì²­' in client:
        return 'ì¡°ë‹¬ì²­'
    elif any(org in client for org in ['ì²­', 'ë¶€', 'ì²˜', 'ì›']) and not any(word in client for word in ['í•™êµ', 'ì§€ì›ì²­']):
        return 'ì¤‘ì•™í–‰ì •ê¸°ê´€'
    
    # ì§€ë°©ìì¹˜ë‹¨ì²´
    if any(word in client for word in ['ì‹œì²­', 'ë„ì²­', 'êµ°ì²­', 'êµ¬ì²­', 'ì‹œì¥', 'ë„ì§€ì‚¬', 'êµ°ìˆ˜', 'êµ¬ì²­ì¥']):
        return 'ì§€ë°©ìì¹˜ë‹¨ì²´'
    
    # ê¸°íƒ€ê³µì‚¬ë¡œ ë¶„ë¥˜ë  ê¸°ê´€ë“¤
    if any(org in client for org in [
        'í•œêµ­ì „ë ¥ê³µì‚¬', 'í•œêµ­ë„ë¡œê³µì‚¬', 'í•œêµ­í† ì§€ì£¼íƒê³µì‚¬', 'í•œêµ­ìˆ˜ìì›ê³µì‚¬',
        'í•œêµ­ì² ë„ê³µì‚¬', 'í•œêµ­ë†ì–´ì´Œê³µì‚¬', 'ëŒ€í•œì„íƒ„ê³µì‚¬', 'í•œêµ­ë§ˆì‚¬íšŒ'
    ]):
        return 'ê¸°íƒ€ê³µì‚¬'
    
    # ê¸°íƒ€ê³µë‹¨ìœ¼ë¡œ ë¶„ë¥˜ ê¸°ê´€ë“¤
    if any(org in client for org in [
        'êµ­ë¯¼ê±´ê°•ë³´í—˜ê³µë‹¨', 'í•œêµ­í™˜ê²½ê³µë‹¨', 'í•œêµ­ì‚°ì—…ë‹¨ì§€ê³µë‹¨',
        'ê·¼ë¡œë³µì§€ê³µë‹¨', 'í•œêµ­ê°€ìŠ¤ê³µë‹¨', 'ë„ë¡œêµí†µê³µë‹¨', 'êµ­ë¯¼ì—°ê¸ˆê³µë‹¨'
    ]):
        return 'ê¸°íƒ€ê³µë‹¨'
    
    # ë‚˜ë¨¸ì§€ëŠ” ê¸°íƒ€ë¡œ ë¶„ë¥˜
    return 'ê¸°íƒ€'

class BidPricePredictor:
    def __init__(self, data):
        # ê²°ì¸¡ì¹˜ê°€ ì—†ëŠ” ë°ì´í„°ë§Œ ì„ íƒ
        required_columns = ['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€', 'ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬', '1ìˆœìœ„ì‚¬ì •ë¥ ']
        self.data = data.dropna(subset=required_columns).copy()
        self.model = None
        self.scaler = StandardScaler()
        self.category_encoder = None  # ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”©ì„ ìœ„í•œ ë³€ìˆ˜ ì¶”ê°€
        
        st.text("=== ëª¨ë¸ ì´ˆê¸°í™” ===")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ì „ì²´ ë°ì´í„° ìˆ˜", f"{len(data):,}ê°œ")
        with col2:
            st.metric("í•™ìŠµ ê°€ëŠ¥í•œ ë°ì´í„° ìˆ˜", f"{len(self.data):,}ê°œ")
    
    def train_model(self):
        try:
            # ìˆ˜ì¹˜í˜• íŠ¹ì„±ê³¼ ë²”ì£¼í˜• íŠ¹ì„± ë¶„ë¦¬
            numeric_features = ['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€']
            categorical_features = ['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬']
            target = '1ìˆœìœ„ì‚¬ì •ë¥ '
            
            # ìˆ˜ì¹˜í˜• íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
            X_numeric = self.data[numeric_features]
            X_numeric_scaled = self.scaler.fit_transform(X_numeric)
            
            # ë²”ì£¼í˜• íŠ¹ì„± ì›-í•« ì¸ì½”ë”©
            X_categorical = pd.get_dummies(self.data[categorical_features], prefix=categorical_features)
            self.category_encoder = {col: idx for idx, col in enumerate(X_categorical.columns)}
            
            # íŠ¹ì„± ê²°í•©
            X = np.hstack([X_numeric_scaled, X_categorical])
            y = self.data[target]
            
            # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
            
            # ëª¨ë¸ í•™ìŠµ
            self.model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42
            )
            self.model.fit(self.X_train, self.y_train)
            
            # íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”
            st.subheader("íŠ¹ì„± ì¤‘ìš”ë„")
            feature_names = numeric_features + list(X_categorical.columns)
            feature_importance_df = pd.DataFrame({
                'íŠ¹ì„±': feature_names,
                'ì¤‘ìš”ë„': self.model.feature_importances_
            })
            
            fig = plot_feature_importance(self.model, feature_importance_df)
            if fig is not None:
                st.pyplot(fig)
            
            return self.model, self.data
            
        except Exception as e:
            st.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return None, None
    
    def predict_rate(self, new_data):
        if self.model is None:
            st.error("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € train_model()ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
            return None
        
        try:
            # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
            if isinstance(new_data, dict):
                new_data = pd.DataFrame([new_data])
            
            # ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ ì¶”ê°€
            if 'ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬' not in new_data.columns and 'ë°œì£¼ì²˜' in new_data.columns:
                new_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'] = new_data['ë°œì£¼ì²˜'].apply(categorize_client)
            
            # ìˆ˜ì¹˜í˜• íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
            numeric_features = ['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€']
            X_numeric = new_data[numeric_features]
            X_numeric_scaled = self.scaler.transform(X_numeric)
            
            # ë²”ì£¼í˜• íŠ¹ì„± ì›-í•« ì¸ì½”ë”©
            X_categorical = pd.get_dummies(new_data[['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬']], prefix=['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'])
            
            # ëˆ„ë½ëœ ì¹´í…Œê³ ë¦¬ ì—´ ì¶”ê°€
            for col in self.category_encoder.keys():
                if col not in X_categorical.columns:
                    X_categorical[col] = 0
            
            # í•™ìŠµ ì‹œ ì‚¬ìš©ëœ ì—´ ìˆœì„œëŒ€ë¡œ ì •ë ¬
            X_categorical = X_categorical[list(self.category_encoder.keys())]
            
            # íŠ¹ì„± ê²°í•©
            X = np.hstack([X_numeric_scaled, X_categorical])
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            predicted = self.model.predict(X)
            
            return predicted[0] if len(predicted) == 1 else predicted
            
        except Exception as e:
            st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return None



def show_category_statistics(data, exclude_lower=99.5, exclude_upper=100.5):
    """ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ë¥¼ ê³„ì‚°í•˜ê³  ê·¸ë˜í”„ë¡œ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        # 1ìˆœìœ„ì‚¬ì •ë¥ ì´ ìˆëŠ” ë°ì´í„°ë§Œ ì„ íƒ
        valid_data = data.dropna(subset=['1ìˆœìœ„ì‚¬ì •ë¥ '])
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ ê³„ì‚°
        stats = valid_data.groupby('ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬').agg({
            '1ìˆœìœ„ì‚¬ì •ë¥ ': [
                ('ê±´ìˆ˜', 'count'),
                ('í‰ê·  ì‚¬ì •ë¥ ', 'mean'),
                ('ìµœì € ì‚¬ì •ë¥ ', 'min'),
                ('ìµœê³  ì‚¬ì •ë¥ ', 'max'),
                ('ì¤‘ì•™ê°’ ì‚¬ì •ë¥ ', 'median'),
                ('í‘œì¤€í¸ì°¨', 'std')
            ]
        })
        
        # ë©€í‹°ì¸ë±ìŠ¤ ì²˜ë¦¬
        stats.columns = stats.columns.droplevel()
        
        # ê±´ìˆ˜ë¡œ ì •ë ¬
        stats = stats.sort_values('ê±´ìˆ˜', ascending=False)
        
        # ì •ê·œë¶„í¬ ë¶„ì„ì„ ìœ„í•œ í•¨ìˆ˜
        def find_top_probabilities(group_data, mean, std, exclude_lower=99.5, exclude_upper=100.5):
            try:
                # 0.01% ë‹¨ìœ„ë¡œ êµ¬ê°„ ìƒì„±
                intervals = np.arange(97, 103, 0.01)
                
                # ì œì™¸ êµ¬ê°„ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
                exclude_start = np.searchsorted(intervals, exclude_lower)
                exclude_end = np.searchsorted(intervals, exclude_upper)
                
                # KDEë¥¼ ì‚¬ìš©í•œ í™•ë¥  ë°€ë„ ì¶”ì •
                kde = gaussian_kde(group_data)
                kde_density = kde(intervals)
                
                # ì‹¤ì œ ë¶„í¬ ê³„ì‚°
                actual_prob = np.array([
                    len(group_data[(group_data >= i) & (group_data < i + 0.01)]) / len(group_data)
                    for i in intervals
                ])
                
                # ì‹¤ì œ í™•ë¥ ì´ KDE ì¶”ì • í™•ë¥ ë³´ë‹¤ ë†’ì€ êµ¬ê°„ ì°¾ê¸°
                prob_diff = actual_prob - kde_density/sum(kde_density)
                
                # ì œì™¸ êµ¬ê°„ì˜ í™•ë¥  ì°¨ì´ë¥¼ -infë¡œ ì„¤ì •í•˜ì—¬ ì„ íƒë˜ì§€ ì•Šë„ë¡ í•¨
                prob_diff[exclude_start:exclude_end] = float('-inf')
                
                # ìƒìœ„ 5ê°œ êµ¬ê°„ ì°¾ê¸°
                top_indices = np.argsort(prob_diff)[-5:][::-1]
                
                # ìƒìœ„ 5ê°œ êµ¬ê°„ê³¼ í™•ë¥  ì°¨ì´ ë°˜í™˜
                top_intervals = [f"{intervals[i]:.2f}" for i in top_indices]
                prob_differences = [f"{prob_diff[i]*100:.2f}" for i in top_indices]
                
                return top_intervals, prob_differences
            except Exception as e:
                st.error(f"KDE ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                return [], []
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì •ê·œë¶„í¬ ë¶„ì„ ìˆ˜í–‰
        for category in stats.index:
            if category != 'ì „ì²´':  # ì „ì²´ ì¹´í…Œê³ ë¦¬ ì œì™¸
                try:
                    group_data = valid_data[valid_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'] == category]['1ìˆœìœ„ì‚¬ì •ë¥ ']
                    if len(group_data) >= 30:  # 30ê°œ ì´ìƒì˜ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ ë¶„ì„
                        mean = stats.loc[category, 'í‰ê·  ì‚¬ì •ë¥ ']
                        std = stats.loc[category, 'í‘œì¤€í¸ì°¨']
                        
                        intervals, prob_diffs = find_top_probabilities(
                            group_data, mean, std, exclude_lower, exclude_upper
                        )
                        
                        # ê²°ê³¼ ì €ì¥
                        for i in range(min(5, len(intervals))):
                            stats.loc[category, f'{i+1}ìˆœìœ„ êµ¬ê°„'] = intervals[i]
                            stats.loc[category, f'{i+1}ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)'] = prob_diffs[i]
                except Exception as e:
                    st.error(f"{category} ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        # ì „ì²´ í†µê³„ ê³„ì‚° ë° ì¶”ê°€
        total_stats = pd.DataFrame({
            'ê±´ìˆ˜': len(valid_data),
            'í‰ê·  ì‚¬ì •ë¥ ': valid_data['1ìˆœìœ„ì‚¬ì •ë¥ '].mean(),
            'ìµœì € ì‚¬ì •ë¥ ': valid_data['1ìˆœìœ„ì‚¬ì •ë¥ '].min(),
            'ìµœê³  ì‚¬ì •ë¥ ': valid_data['1ìˆœìœ„ì‚¬ì •ë¥ '].max(),
            'ì¤‘ì•™ê°’ ì‚¬ì •ë¥ ': valid_data['1ìˆœìœ„ì‚¬ì •ë¥ '].median(),
            'í‘œì¤€í¸ì°¨': valid_data['1ìˆœìœ„ì‚¬ì •ë¥ '].std()
        }, index=['ì „ì²´'])
        
        # ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ì •ê·œë¶„í¬ ë¶„ì„ ìˆ˜í–‰
        try:
            mean = total_stats.loc['ì „ì²´', 'í‰ê·  ì‚¬ì •ë¥ ']
            std = total_stats.loc['ì „ì²´', 'í‘œì¤€í¸ì°¨']
            intervals, prob_diffs = find_top_probabilities(valid_data['1ìˆœìœ„ì‚¬ì •ë¥ '], mean, std)
            
            # ê²°ê³¼ ì €ì¥
            for i in range(min(5, len(intervals))):
                total_stats.loc['ì „ì²´', f'{i+1}ìˆœìœ„ êµ¬ê°„'] = intervals[i]
                total_stats.loc['ì „ì²´', f'{i+1}ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)'] = prob_diffs[i]
        except Exception as e:
            st.error(f"ì „ì²´ í†µê³„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ê°’ìœ¼ë¡œ ì„¤ì •
            for i in range(5):
                total_stats[f'{i+1}ìˆœìœ„ êµ¬ê°„'] = ''
                total_stats[f'{i+1}ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)'] = ''
        
        # ì „ì²´ í†µê³„ë¥¼ ë§ˆì§€ë§‰ í–‰ìœ¼ë¡œ ì¶”ê°€
        stats = pd.concat([stats, total_stats])
        
        # í†µê³„ í…Œì´ë¸” í‘œì‹œ
        st.dataframe(
            stats.style.format({
                'ê±´ìˆ˜': '{:,.0f}',
                'í‰ê·  ì‚¬ì •ë¥ ': '{:.4f}%',
                'ìµœì € ì‚¬ì •ë¥ ': '{:.4f}%',
                'ìµœê³  ì‚¬ì •ë¥ ': '{:.4f}%',
                'ì¤‘ì•™ê°’ ì‚¬ì •ë¥ ': '{:.4f}%',
                'í‘œì¤€í¸ì°¨': '{:.4f}',
                '1ìˆœìœ„ êµ¬ê°„': '{}',
                '2ìˆœìœ„ êµ¬ê°„': '{}',
                '3ìˆœìœ„ êµ¬ê°„': '{}',
                '4ìˆœìœ„ êµ¬ê°„': '{}',
                '5ìˆœìœ„ êµ¬ê°„': '{}',
                '1ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)': '{}',
                '2ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)': '{}',
                '3ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)': '{}',
                '4ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)': '{}',
                '5ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)': '{}'
            }).set_properties(subset=pd.IndexSlice['ì „ì²´', :], 
                            **{'background-color': 'grey'}),
            use_container_width=True
        )
        
        return stats
        
    except Exception as e:
        st.error(f"ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# í•œê¸€ í°íŠ¸ ì„¤ì •
def setup_korean_font():
    """í•œê¸€ í°íŠ¸ ì„¤ì • í•¨ìˆ˜"""
    system_name = platform.system()
    
    try:
        if system_name == "Windows":
            plt.rcParams['font.family'] = 'Malgun Gothic'
        elif system_name == "Darwin":  # macOS
            plt.rcParams['font.family'] = 'AppleGothic'
        else:  # Linux
            # ë‚˜ëˆ”ê³ ë”• í°íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ì„¤ì¹˜
            import subprocess
            try:
                subprocess.run(['fc-list', ':lang=ko'], check=True)
            except:
                subprocess.run(['apt-get', 'install', '-y', 'fonts-nanum'], check=True)
            plt.rcParams['font.family'] = 'NanumGothic'
        
        plt.rcParams['axes.unicode_minus'] = False
        
    except Exception as e:
        st.warning(f"í•œê¸€ í°íŠ¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False

# íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”
def plot_feature_importance(model, feature_importance_df):
    """íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # í•œê¸€ í°íŠ¸ ì„¤ì •
        setup_korean_font()
        
        # íŠ¹ì„± ì¤‘ìš”ë„ ì •ë ¬
        feature_importance = feature_importance_df.sort_values('ì¤‘ìš”ë„', ascending=True)
        
        # ìƒìœ„ 15ê°œ íŠ¹ì„±ë§Œ ì„ íƒ
        top_features = feature_importance.tail(15)
        
        # ê·¸ë˜í”„ ìƒì„±
        fig, ax = plt.subplots(figsize=(12, 6))
        
        # ìˆ˜í‰ ë§‰ëŒ€ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        bars = ax.barh(range(len(top_features)), top_features['ì¤‘ìš”ë„'], 
                      color='steelblue', alpha=0.8)
        
        # yì¶• ë ˆì´ë¸” ì„¤ì •
        ax.set_yticks(range(len(top_features)))
        ax.set_yticklabels(top_features['íŠ¹ì„±'])
        
        # ë§‰ëŒ€ ëì— ê°’ í‘œì‹œ
        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax.text(width, bar.get_y() + bar.get_height()/2, 
                   f'{width:.4f}', 
                   ha='left', va='center', fontsize=9)
        
        # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ë§
        ax.set_title('íŠ¹ì„± ì¤‘ìš”ë„', pad=20, fontsize=12)
        ax.set_xlabel('ì¤‘ìš”ë„', labelpad=10)
        
        # ê·¸ë¦¬ë“œ ì¶”ê°€
        ax.grid(True, axis='x', alpha=0.3)
        
        # ì—¬ë°± ì¡°ì •
        plt.tight_layout()
        
        return fig
        
    except Exception as e:
        st.error(f"íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
def plot_prediction_distribution(predictions):
    # í•œê¸€ í°íŠ¸ ì„¤ì •
    setup_korean_font()
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    # íˆìŠ¤í† ê·¸ë¨ ê·¸ë¦¬ê¸°
    n, bins, patches = ax.hist(predictions, bins=50, 
                             color='steelblue', alpha=0.8,
                             edgecolor='white')
    
    # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ë§
    ax.set_title('ì˜ˆì¸¡ëœ 1ìˆœìœ„ì‚¬ì •ë¥  ë¶„í¬', pad=20)
    ax.set_xlabel('1ìˆœìœ„ì‚¬ì •ë¥  (%)', labelpad=10)
    ax.set_ylabel('ë¹ˆë„ìˆ˜', labelpad=10)
    
    # xì¶• ë²”ìœ„ ì„¤ì •
    ax.set_xlim(97, 103)
    
    # ê·¸ë¦¬ë“œ ì¶”ê°€
    ax.grid(True, alpha=0.3)
    
    # ì—¬ë°± ì¡°ì •
    plt.tight_layout()
    
    return fig

########################################################

# ë‘ ë²ˆì§¸ ì…€ - ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬

# ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def convert_to_numeric(x):
    if pd.isna(x):
        return np.nan
    if isinstance(x, str):
        x = x.replace(',', '').strip()
        if '%' in x:
            return float(x.replace('%', '')) / 100
    return pd.to_numeric(x, errors='coerce')

def reclassify_small_categories(data, min_count=30):
    """ì¹´í…Œê³ ë¦¬ ì¬ë¶„ë¥˜í•˜ëŠ” í•¨ìˆ˜"""
    # ë°ì´í„° ë³µì‚¬
    reclassified_data = data.copy()
    
    # ì¹´í…Œê³ ë¦¬ë³„ ê±´ìˆ˜ ê³„ì‚°
    category_counts = reclassified_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'].value_counts()
    
    # 30ê±´ ë¯¸ë§Œì¸ ì¹´í…Œê³ ë¦¬ ì‹ë³„
    small_categories = category_counts[category_counts < min_count].index
    
    # ì¬ë¶„ë¥˜ ê·œì¹™ ì •ì˜
    reclassification_rules = {
        # ê¸°íƒ€ê³µì‚¬ë¡œ í†µí•©
        'í•œêµ­ì „ë ¥ê³µì‚¬': 'ê¸°íƒ€ê³µì‚¬',
        'í•œêµ­ë„ë¡œê³µì‚¬': 'ê¸°íƒ€ê³µì‚¬',
        'í•œêµ­í† ì§€ì£¼íƒê³µì‚¬': 'ê¸°íƒ€ê³µì‚¬',
        'í•œêµ­ë§ˆì‚¬íšŒ': 'ê¸°íƒ€ê³µì‚¬',
        
        # ê¸°íƒ€ê³µë‹¨ìœ¼ë¡œ í†µí•©
        'êµ­ë¯¼ê±´ê°•ë³´í—˜ê³µë‹¨': 'ê¸°íƒ€ê³µë‹¨',
        
        # ê¸°íƒ€ë¡œ í†µí•©
        'í˜‘íšŒì¡°í•©': 'ê¸°íƒ€',
        'ê³µê³µê¸°ê´€': 'ê¸°íƒ€',
        
        # í•™êµëŠ” ë” ì´ìƒ êµìœ¡ì²­ìœ¼ë¡œ í†µí•©í•˜ì§€ ì•ŠìŒ
        'ê²½ì°°ì†Œë°©': 'ê³µê³µê¸°ê´€',
        'ì—°êµ¬ê¸°ê´€': 'ê³µê³µê¸°ê´€',
        'ì˜ë£Œê¸°ê´€': 'ê³µê³µê¸°ê´€'
    }
    
    # ë¨¼ì € 30ê±´ ë¯¸ë§Œì¸ ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬
    for category in small_categories:
        if category in reclassification_rules:
            # ê·œì¹™ì´ ìˆëŠ” ê²½ìš° í•´ë‹¹ ê·œì¹™ ì ìš©
            mask = reclassified_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'] == category
            reclassified_data.loc[mask, 'ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'] = reclassification_rules[category]
        else:
            # ê·œì¹™ì´ ì—†ëŠ” ê²½ìš° 'ê¸°íƒ€'ë¡œ ë¶„ë¥˜
            mask = reclassified_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'] == category
            reclassified_data.loc[mask, 'ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'] = 'ê¸°íƒ€'
    
    # ë‚˜ë¨¸ì§€ ì¬ë¶„ë¥˜ ê·œì¹™ ì ìš©
    for old_category, new_category in reclassification_rules.items():
        if old_category not in small_categories:  # ì´ë¯¸ ì²˜ë¦¬ëœ ì¹´í…Œê³ ë¦¬ëŠ” ì œì™¸
            mask = reclassified_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'] == old_category
            reclassified_data.loc[mask, 'ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'] = new_category
    
    return reclassified_data

def load_and_preprocess_data():
    try:
        # ë°ì´í„° í´ë” ê²½ë¡œ ì„¤ì •
        data_folder = os.path.dirname(os.path.abspath(__file__))
        
        # ì…ì°°ì •ë³´ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        bid_files = [os.path.join(data_folder, f'bid_info_{i}.xlsx') for i in range(1, 6)]
        existing_bid_files = [f for f in bid_files if os.path.exists(f)]
        
        if not existing_bid_files:
            st.error("ì…ì°°ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        # ì…ì°°ì •ë³´ íŒŒì¼ ì½ê¸°
        bid_dfs = []
        for file in existing_bid_files:
            try:
                df = pd.read_excel(file, header=1)
                if not df.empty:
                    bid_dfs.append(df)
            except Exception as e:
                continue
        
        if not bid_dfs:
            st.error("ì½ì„ ìˆ˜ ìˆëŠ” ì…ì°°ì •ë³´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        # ì…ì°°ì •ë³´ ë³‘í•© ë° ì¤‘ë³µ ì œê±°
        merged_bid = pd.concat(bid_dfs, axis=0, ignore_index=True)
        
        # ì¤‘ë³µ ì œê±° ì „ ë°ì´í„° ìˆ˜ ì €ì¥
        before_drop_duplicates = len(merged_bid)
        
        # ê³µê³ ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±° (ìµœì‹  ë°ì´í„° ìœ ì§€)
        merged_bid = merged_bid.sort_values('ê°œì°°ì¼', ascending=False)  # ìµœì‹  ë°ì´í„°ê°€ ìœ„ë¡œ ì˜¤ë„ë¡ ì •ë ¬
        merged_bid = merged_bid.drop_duplicates(subset=['ê³µê³ ë²ˆí˜¸'], keep='first')
        
        # ì¤‘ë³µ ì œê±° í›„ ë°ì´í„° ìˆ˜ ê³„ì‚°
        after_drop_duplicates = len(merged_bid)
        removed_duplicates = before_drop_duplicates - after_drop_duplicates
        
        if removed_duplicates > 0:
            st.info(f"ì¤‘ë³µëœ ê³µë²ˆí˜¸ {removed_duplicates}ê°œê°€ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤. (ì „ì²´: {before_drop_duplicates}ê°œ â†’ {after_drop_duplicates}ê°œ)")
        
        try:
            # ë‚™ì°°ì •ë³´ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ì˜ë¬¸ íŒŒì¼ëª… ì‚¬ìš©)
            award_files = [os.path.join(data_folder, f'award_info_{i}.xlsx') for i in range(1, 6)]
            existing_award_files = [f for f in award_files if os.path.exists(f)]
            
            award_dfs = []
            if existing_award_files:  # ë‚™ì°°ì •ë³´ íŒŒì¼ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì²˜ë¦¬
                for file in existing_award_files:
                    try:
                        df = pd.read_excel(file, header=1)
                        if not df.empty:
                            award_dfs.append(df)
                    except Exception as e:
                        st.warning(f"ë‚™ì°°ì •ë³´ íŒŒì¼ '{file}' ì½ê¸° ì‹¤íŒ¨: {str(e)}")
                        continue
            
            if award_dfs:  # ë‚™ì •ë³´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ë³‘í•©
                merged_award = pd.concat(award_dfs, axis=0, ignore_index=True)
                
                # ë‚™ì°°ì •ë³´ë„ ì¤‘ë³µ ì œê±° (ìµœì‹  ë°ì´í„° ìœ ì§€)
                before_award_duplicates = len(merged_award)
                merged_award = merged_award.drop_duplicates(subset=['ê³µê³ ë²ˆí˜¸'], keep='first')
                after_award_duplicates = len(merged_award)
                removed_award_duplicates = before_award_duplicates - after_award_duplicates
                
                if removed_award_duplicates > 0:
                    st.info(f"ë‚™ì°°ì •ë³´ì—ì„œ ì¤‘ë³µëœ ê³µê³ ë²ˆí˜¸ {removed_award_duplicates}ê°œê°€ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                # ì…ì°°ì •ë³´ì™€ ë‚™ì°°ì •ë³´ ë³‘í•©
                columns_to_use = [col for col in merged_award.columns if col not in merged_bid.columns or col == 'ê³µê³ ë²ˆí˜¸']
                merged_data = pd.merge(
                    merged_bid,
                    merged_award[columns_to_use],
                    on='ê³µê³ ë²ˆí˜¸',
                    how='left'
                )
            else:
                merged_data = merged_bid
                st.info("ë‚™ì°°ì •ë³´ íŒŒì¼ì´ ì—†ê±°ë‚˜ ì½ì„ ìˆ˜ ì—†ì–´ ì…ì°°ì •ë³´ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        except Exception as e:
            st.warning(f"ë‚™ì°°ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            merged_data = merged_bid
        
        # ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ ì¶”ê°€ ë° ì¬ë¶„ë¥˜ë¥¼ í•œ ë²ˆë§Œ ìˆ˜í–‰
        merged_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'] = merged_data['ë°œì£¼ì²˜'].apply(categorize_client)
        merged_data = reclassify_small_categories(merged_data)
        
        # ìˆ«ìí˜• ë³€í™˜
        numeric_columns = ['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€', '1ìˆœìœ„ì‚¬ì •ë¥ ']
        for col in numeric_columns:
            if col in merged_data.columns:
                merged_data[col] = merged_data[col].apply(convert_to_numeric)
        
        return merged_data
        
    except Exception as e:
        st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return pd.DataFrame()

# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì‹¤í–‰
processed_data = load_and_preprocess_data()

########################################################
# ì›¹ì— ë°ì´í„° í”„ë ˆì„ í‘œì‹œ
st.title('ë‚˜ë¼ì¥í„° íˆ¬ì°°ì„ ìœ„í•œ ì‚¬ì •ë¥  êµ¬í•˜ê¸°')

# ë°ì´í„° í”„ë ˆì„ í‘œì‹œ    
st.header("1. 2021ë…„ 01ì›” ì´í›„ ë‚˜ë¼ì¥í„° ì…ì°° ë° ë‚™ì°° ì •ë³´", divider=True)

st.dataframe(processed_data, use_container_width=False)
# ë°ì´í„° ì •ë³´ í‘œì‹œ
st.caption(f"ì „ì²´ {len(processed_data):,}ê°œì˜ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

########################################################
# íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ë“¤ì„ ë‚˜ëˆ„ì–´ ë°°ì¹˜
col1, col2 = st.columns(2)

with col1:
    st.subheader("ìƒˆë¡œìš´ ì…ì°° ë°ì´í„° ì—…ë¡œë“œ")
    bid_file = st.file_uploader("ì…ì°° ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['xlsx', 'xls'], key='bid_upload')
    
    if bid_file is not None:
        try:
            # ê¸°ì¡´ì˜ ì…ì°° ë°ì´í„° ì—…ë¡œë“œ ë¡œì§
            new_data = pd.read_excel(bid_file, header=1)
            
            # ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ ì¶”ê°€
            new_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'] = new_data['ë°œì£¼ì²˜'].apply(categorize_client)
            
            # ì¹´í…Œê³ ë¦¬ ì¼ê´€ì„± ê²€ì‚¬
            unique_categories = new_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'].unique()
            st.text("=== ìƒˆë¡œìš´ ë°ì´í„°ì˜ ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ ===")
            for category in unique_categories:
                count = len(new_data[new_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'] == category])
                st.text(f"{category}: {count}ê±´")
            
            # # ë°ì´í„° í™•ì¸ì„ ìœ„í•œ ì •ë³´ ì¶œë ¥
            # st.write("ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì—´:", new_data.columns.tolist())
            
            required_columns = ['ê³µê³ ë²ˆí˜¸'] + ['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€']
            missing_columns = set(required_columns) - set(new_data.columns)
            
            if missing_columns:
                st.error(f"í•„ìˆ˜ ì—´ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_columns)}")
            else:
                # ì—…ë°ì´íŠ¸ ì „ ë°ì´í„° ìƒíƒœ í™•ì¸
                before_count = len(processed_data)
                before_empty = processed_data['1ìˆœìœ„ì‚¬ì •ë¥ '].isna().sum()
                
                # ìˆ«ìí˜• ë°ì´í„° ë³€í™˜
                numeric_columns = ['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€']
                for col in numeric_columns:
                    if col in new_data.columns:
                        new_data[col] = new_data[col].apply(convert_to_numeric)
                
                # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•© (ì¤‘ë³µ ì œê±°)
                processed_data = pd.concat([processed_data, new_data], axis=0)
                processed_data = processed_data.drop_duplicates(subset=['ê³µê³ ë²ˆí˜¸'], keep='first')
                
                # ì—…ë°ì´íŠ¸ í›„ ë°ì´í„° ìƒíƒœ í™•ì¸
                after_count = len(processed_data)
                after_empty = processed_data['1ìˆœìœ„ì‚¬ì •ë¥ '].isna().sum()
                update_count = after_count - before_count
                
                st.success(f"""
                ì…ì°° ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.
                - ì¶”ê°€ëœ ìƒˆë¡œìš´ í–‰ ìˆ˜: {update_count}ê°œ
                - ì—…ë°ì´íŠ¸ ì „ ì „ì²´ í–‰ ìˆ˜: {before_count}ê°œ
                - ì—…ë°ì´íŠ¸ í›„ ì „ì²´ í–‰ ìˆ˜: {after_count}ê°œ
                - ì—…ë°ì´íŠ¸ ì „ ë¹ˆ ê°’: {before_empty}ê°œ
                - ì—…ë°ì´íŠ¸ í›„ ë¹ˆ ê°’: {after_empty}ê°œ
                """)
                
        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.write("ì˜¤ë¥˜ ìƒì„¸:", str(e))

with col2:
    st.subheader("ìƒˆë¡œìš´ ë‚™ì°° ë°ì´í„° ì—…ë¡œë“œ")
    award_file = st.file_uploader("ë‚™ì°° ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['xlsx', 'xls'], key='award_upload')
    
    if award_file is not None:
        try:
            # ìƒˆë¡œìš´ ë‚™ì°° ë°ì´í„° ì½ê¸°
            new_award_data = pd.read_excel(award_file, header=1)
            
            # í•„ìˆ˜ ì—´ í™•ì¸
            required_columns = ['ê³µê³ ë²ˆí˜¸', '1ìˆœìœ„ì‚¬ì •ë¥ ']
            missing_columns = set(required_columns) - set(new_award_data.columns)
            
            if missing_columns:
                st.error(f"í•„ìˆ˜ ì—´ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_columns)}")
            else:
                # ìˆ«ìí˜• ë°ì´í„° ë³€í™˜
                if '1ìˆœìœ„ì‚¬ì •ë¥ ' in new_award_data.columns:
                    new_award_data['1ìˆœìœ„ì‚¬ì •ë¥ '] = new_award_data['1ìˆœìœ„ì‚¬ì •ë¥ '].apply(convert_to_numeric)
                
                # ì—…ë°ì´íŠ¸ ì „ ë°ì´í„° ìƒíƒœ í™•ì¸
                before_empty = processed_data['1ìˆœìœ„ì‚¬ì •ë¥ '].isna().sum()
                
                # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆë¡œìš´ ë°ì´í„°ì˜ ê³µê³ ë²ˆí˜¸ ë§¤ì¹­
                update_count = 0
                for idx, row in new_award_data.iterrows():
                    mask = (processed_data['ê³µê³ ë²ˆí˜¸'] == row['ê³µê³ ë²ˆí˜¸']) & \
                          (pd.isna(processed_data['1ìˆœìœ„ì‚¬ì •ë¥ ']))
                    
                    if mask.any():
                        # ë¹ˆ ê°’ë§Œ ì—…ë°ì´íŠ¸
                        for col in new_award_data.columns:
                            if col in processed_data.columns and col != 'ê³µê³ ë²ˆí˜¸':
                                processed_data.loc[mask, col] = row[col]
                        update_count += 1
                
                # ì—…ë°ì´íŠ¸ í›„ ë°ì´í„° ìƒíƒœ í™•ì¸
                after_empty = processed_data['1ìˆœìœ„ì‚¬ì •ë¥ '].isna().sum()
                
                st.success(f"""
                ë‚™ì°° ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.
                - ì—…ë°ì´íŠ¸ëœ í–‰ ìˆ˜: {update_count}ê°œ
                - ì—…ë°ì´íŠ¸ ì „ ë¹ˆ ê°’: {before_empty}ê°œ
                - ì—…ë°ì´íŠ¸ í›„ ë¹ˆ ê°’: {after_empty}ê°œ
                """)
                
                # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                st.session_state['processed_data'] = processed_data
                
        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.write("ì˜¤ë¥˜ ìƒì„¸:", str(e))

# í†µê³„ ì—…ë°ì´íŠ¸ ë²„íŠ¼ ì¶”ê°€
if st.button("ğŸ“Š í†µê³„ ë°ì´í„° ì—…ë°ì´íŠ¸", type="primary"):
    with st.spinner("í†µê³„ ë°ì´í„° ì—…ë°ì´íŠ¸ ì¤‘..."):
        try:
            # ì „ì²´ ë°ì´í„°ì˜ ì¹´í…Œê³ ë¦¬ë³„ ê±´ìˆ˜ ì¬ê³„ì‚°
            total_counts = processed_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'].value_counts()
            
            # í˜„ì¬ ì„¤ì •ëœ ì œì™¸ êµ¬ê°„ ê°’ ê°€ì ¸ì˜¤ê¸°
            exclude_lower = st.session_state.get('exclude_lower', 99.5)
            exclude_upper = st.session_state.get('exclude_upper', 100.5)
            
            # 1ìˆœìœ„ì‚¬ì •ë¥  í†µê³„ ì¬ê³„ì‚°
            category_stats = show_category_statistics(processed_data, exclude_lower, exclude_upper)
            
            # ì„¸ì…˜ ìƒíƒœì— ì—…ë°ì´íŠ¸ëœ ë°ì´í„° ì €ì¥
            st.session_state['processed_data'] = processed_data
            st.session_state['total_counts'] = total_counts
            st.session_state['category_stats'] = category_stats
            
            st.success("í†µê³„ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # í†µê³„ í‘œì‹œ ë¶€ë¶„ ì—…ë°ì´íŠ¸
            st.subheader("ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ë³„ 1ìˆœìœ„ì‚¬ì •ë¥  í†µê³„")
            if category_stats is not None:
                st.dataframe(
                    category_stats.style.format({
                        'ê±´ìˆ˜': '{:,.0f}',
                        'í‰ê·  ì‚¬ì •ë¥ ': '{:.4f}%',
                        'ìµœì € ì‚¬ì •ë¥ ': '{:.4f}%',
                        'ìµœê³  ì‚¬ì •ë¥ ': '{:.4f}%',
                        'ì¤‘ì•™ê°’ ì‚¬ì •ë¥ ': '{:.4f}%',
                        'í‘œì¤€í¸ì°¨': '{:.4f}',
                        '1ìˆœìœ„ êµ¬ê°„': '{}',
                        '2ìˆœìœ„ êµ¬ê°„': '{}',
                        '3ìˆœìœ„ êµ¬ê°„': '{}',
                        '4ìˆœìœ„ êµ¬ê°„': '{}',
                        '5ìˆœìœ„ êµ¬ê°„': '{}',
                        '1ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)': '{}',
                        '2ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)': '{}',
                        '3ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)': '{}',
                        '4ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)': '{}',
                        '5ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)': '{}'
                    }).set_properties(subset=pd.IndexSlice['ì „ì²´', :], 
                                    **{'background-color': 'lightgray'}),
                    use_container_width=True
                )
            
            # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
            st.rerun()
            
        except Exception as e:
            st.error(f"í†µê³„ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

########################################################
# ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
st.text("\n=== ë°ì´í„° ë‹¤ìš´ë¡œë“œ ===")
# BytesIOë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ì— ì—‘ì…€ íŒŒì¼ ìƒì„±
from io import BytesIO
import xlsxwriter

def to_excel(df):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, sheet_name='Sheet1', index=False)
        # ìë™ ì—´ ë„ˆë¹„ ì¡°ì •
        worksheet = writer.sheets['Sheet1']
        for i, col in enumerate(df.columns):
            column_len = max(df[col].astype(str).apply(len).max(), len(col)) + 2
            worksheet.set_column(i, i, column_len)
    output.seek(0)
    return output

# ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„±
excel_file = to_excel(processed_data)
st.download_button(
    label="ğŸ“¥ ì—…ë°ì´íŠ¸ëœ ë°ì´í„° ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
    data=excel_file,
    file_name='ë‚˜ë¼ì¥í„°_ì…ì°°ì •ë³´.xlsx',
    mime='application/vnd.ms-excel'
)

# ë°ì´í„° ì •ë³´ í‘œì‹œ
st.caption(f"ì „ì²´ {len(processed_data):,}ê°œì˜ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

########################################################
# ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ í‘œì‹œ
st.header("2. ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ë³„ í†µê³„", divider=True)

# ì •ê·œë¶„í¬ ë¶„ì„ êµ¬ê°„ ì„¤ì •
st.subheader("ì •ê·œë¶„í¬ ë¶„ì„ êµ¬ê°„ ì„¤ì •")
col1, col2 = st.columns(2)
with col1:
    exclude_lower = st.number_input(
        "ì œì™¸í•  êµ¬ê°„ í•˜í•œê°’ (%)",
        min_value=97.0,
        max_value=100.0,
        value=st.session_state.get('exclude_lower', 99.5),
        step=0.1,
        format="%.1f",
        key='exclude_lower'
    )
with col2:
    exclude_upper = st.number_input(
        "ì œì™¸í•  êµ¬ê°„ ìƒí•œê°’ (%)",
        min_value=100.0,
        max_value=103.0,
        value=st.session_state.get('exclude_upper', 100.5),
        step=0.1,
        format="%.1f",
        key='exclude_upper'
    )

# ì„¸ì…˜ ìƒíƒœì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
if 'processed_data' in st.session_state:
    processed_data = st.session_state['processed_data']

# í†µê³„ ì—…ë°ì´íŠ¸ í™•ì¸
if st.session_state.get('update_stats', False):
    # ì „ì²´ ë°ì´í„°ì˜ ì¹´í…Œê³ ë¦¬ë³„ ê±´ìˆ˜ ì¬ê³„ì‚°
    total_counts = processed_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'].value_counts()
    
    # 1ìˆœìœ„ì‚¬ì •ë¥  í†µê³„ ì¬ê³„ì‚°
    category_stats = show_category_statistics(processed_data, exclude_lower, exclude_upper)
    
    # ì—…ë°ì´íŠ¸ í”Œë˜ê·¸ ì´ˆê¸°í™”
    st.session_state['update_stats'] = False

# ì „ì²´ ë°ì´í„°ì˜ ì¹´í…Œê³ ë¦¬ë³„ ê±´ìˆ˜
total_counts = processed_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'].value_counts()
# st.text("\n=== ì „ì²´ ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ë³„ ê±´ìˆ˜ ===")
# for category, count in total_counts.items():
#     st.text(f"{category}: {count:,}ê±´")

# 1ìˆœìœ„ì‚¬ì •ë¥ ì´ ìˆëŠ” ë°ì´í„°ì˜ í†µê³„
st.subheader("ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ë³„ 1ìˆœìœ„ì‚¬ì •ë¥  í†µê³„")
category_stats = show_category_statistics(processed_data, exclude_lower, exclude_upper)

########################################################
def plot_category_distribution(data, category=None):
    """ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ë³„ í™•ë¥ ë¶„í¬ì™€ ì‹¤ì œ ë¶„í¬ë¥¼ ë¹„êµí•˜ëŠ” ê·¸ë˜í”„"""
    try:
        # ê·¸ë˜í”„ ìƒì„± ì „ í•œê¸€ í°íŠ¸ ì„¤ì •
        setup_korean_font()
        plt.clf()  # ì´ì „ ê·¸ë˜í”„ ì´ˆê¸°í™”
        
        # ë°ì´í„° í•„í„°ë§
        if category == 'ì „ì²´':
            category_data = data['1ìˆœìœ„ì‚¬ì •ë¥ '].dropna()
        else:
            category_data = data[data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'] == category]['1ìˆœìœ„ì‚¬ì •ë¥ '].dropna()
        
        if len(category_data) == 0:
            st.warning(f"{category} ì¹´í…Œê³ ë¦¬ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # 0.01% ë‹¨ìœ„ë¡œ êµ¬ê°„ ìƒì„±
        intervals = np.arange(97, 103, 0.01)
        
        # ì‹¤ì œ ë¶„í¬ ê³„ì‚° (í™•ë¥  ë°€ë„ë¡œ ë³€í™˜)
        total_samples = len(category_data)
        actual_counts = []
        for i in intervals:
            count = len(category_data[(category_data >= i) & (category_data < i + 0.01)])
            actual_counts.append(count / total_samples / 0.01)  # í™•ë¥  ë°€ë„ë¡œ ë³€í™˜
        
        # KDEë¥¼ ì‚¬ìš©í•œ í™•ë¥  ë°€ë„ ì¶”ì •
        kde = gaussian_kde(category_data)
        kde_density = kde(intervals)
        
        # ê·¸ë˜í”„ ìƒì„±
        fig, ax = plt.subplots(figsize=(15, 8))
        
        # í°íŠ¸ í¬ê¸° ì¡°ì •
        plt.rcParams['font.size'] = 12
        plt.rcParams['axes.titlesize'] = 14
        plt.rcParams['axes.labelsize'] = 12
        plt.rcParams['legend.fontsize'] = 10
        
        # ì‹¤ì œ ë¶„í¬ ê·¸ë˜í”„
        ax.plot(intervals, actual_counts, color='steelblue', 
               label='ì‹¤ì œ í™•ë¥ ë¶„í¬', linewidth=2, alpha=0.7)
        
        # KDE ê·¸ë˜í”„
        ax.plot(intervals, kde_density, color='red', 
               label='KDE ì¶”ì • í™•ë¥ ë¶„í¬', linewidth=2, 
               linestyle='--', alpha=0.7)
        
        # í‰ê· ê³¼ í‘œì¤€í¸ì°¨ í‘œì‹œ
        mean = category_data.mean()
        std = category_data.std()
        ax.axvline(mean, color='green', linestyle='-', alpha=0.5, 
                  label=f'í‰ê· : {mean:.4f}%')
        ax.axvline(mean - std, color='orange', linestyle=':', alpha=0.5, 
                  label=f'í‰ê·  Â± í‘œì¤€í¸ì°¨\n({mean-std:.4f}% ~ {mean+std:.4f}%)')
        ax.axvline(mean + std, color='orange', linestyle=':', alpha=0.5)
        
        # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ë§
        ax.set_title(f'{category} ì¹´í…Œê³ ë¦¬ì˜ 1ìˆœìœ„ì‚¬ì •ë¥  í™•ë¥ ë¶„í¬', pad=20)
        ax.set_xlabel('1ìˆœìœ„ì‚¬ì •ë¥  (%)', labelpad=10)
        ax.set_ylabel('í™•ë¥  ë°€ë„', labelpad=10)
        ax.grid(True, alpha=0.3)
        ax.legend(loc='upper left', bbox_to_anchor=(1, 1))
        
        # ì—¬ë°± ì¡°ì • ì „ ë ˆì´ì•„ì›ƒ ìµœì í™”
        plt.tight_layout(rect=[0, 0, 0.85, 1])  # ë²”ë¡€ë¥¼ ìœ„í•œ ì—¬ë°± í™•ë³´
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        distribution_df = pd.DataFrame({
            'ì‚¬ì •ë¥ (%)': intervals,
            'KDEì¶”ì •_í™•ë¥ ë°€ë„': kde_density,
            'ì‹¤ì œ_í™•ë¥ ë°€ë„': actual_counts
        })
        
        # í†µê³„ ì •ë³´ ì¶”ê°€
        stats_df = pd.DataFrame({
            'í†µê³„ëŸ‰': ['í‰ê· ', 'í‘œì¤€í¸ì°¨', 'ì¤‘ì•™ê°’', 'ìµœë¹ˆê°’', 'ì™œë„', 'ì²¨ë„'],
            'ê°’': [
                f"{mean:.4f}%",
                f"{std:.4f}",
                f"{category_data.median():.4f}%",
                f"{category_data.mode().iloc[0]:.4f}%",
                f"{category_data.skew():.4f}",
                f"{category_data.kurtosis():.4f}"
            ]
        })
        
        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë¶€ë¶„ ìˆ˜ì •
        def create_excel_download(distribution_df, stats_df, category):
            """ì—‘ì…€ íŒŒì¼ ìƒì„± í•¨ìˆ˜"""
            output = BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                # í™•ë¥ ë¶„í¬ ì‹œíŠ¸
                distribution_df.to_excel(writer, sheet_name='í™•ë¥ ë¶„í¬', index=False)
                
                # í†µê³„ì •ë³´ ì‹œíŠ¸
                stats_df.to_excel(writer, sheet_name='í†µê³„ì •ë³´', index=False)
                
                # ìë™ ì—´ ë„ˆë¹„ ì¡°ì •
                for sheet in writer.sheets.values():
                    for idx, col in enumerate(distribution_df.columns):
                        column_len = max(distribution_df[col].astype(str).apply(len).max(), len(col)) + 2
                        sheet.set_column(idx, idx, column_len)
            
            output.seek(0)
            return output
        
        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        excel_data = create_excel_download(distribution_df, stats_df, category)
        st.download_button(
            label=f"ğŸ“¥ {category} ì¹´í…Œê³ ë¦¬ì˜ í™•ë¥ ë¶„í¬ ë°ì´í„° ë‹¤ìš´ë¡œë“œ",
            data=excel_data,
            file_name=f'{category}_distribution_analysis.xlsx',
            mime='application/vnd.ms-excel'
        )
        
        # í†µê³„ ì •ë³´ í‘œì‹œ
        st.text("\n=== ë¶„í¬ íŠ¹ì„± ===")
        st.dataframe(stats_df, use_container_width=True)
        
        return fig
        
    except Exception as e:
        st.error(f"ë¶„í¬ ê·¸ë˜í”„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ í‘œì‹œ ë¶€ë¶„ì— ì¶”ê°€
st.subheader("ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ë³„ 1ìˆœìœ„ì‚¬ì •ë¥  ë¶„í¬")

# ì¹´í…Œê³ ë¦¬ ì„ íƒ ë°•ìŠ¤
categories = ['ì „ì²´'] + list(total_counts.index)
selected_category = st.selectbox('ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ ì„ íƒ', categories)

# ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì˜ ë¶„í¬ ê·¸ë˜í”„ í‘œì‹œ
fig = plot_category_distribution(processed_data, selected_category)
if fig is not None:
    st.pyplot(fig)

########################################################
st.header("3. ì‚¬ì •ë¥  ì˜ˆì¸¡ ëª¨ë¸", divider=True)

# ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©í•  ì™„ì „í•œ ë°ì´í„° í™•ì¸
complete_data = processed_data.dropna(subset=['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€', '1ìˆœìœ„ì‚¬ì •ë¥ '])

# ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë²„íŠ¼
if st.button("ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ì‹œì‘", type="primary"):
    with st.spinner("ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ì¤‘..."):
        try:
            # ì˜ˆì¸¡ ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ
            predictor = BidPricePredictor(processed_data)
            model, valid_data = predictor.train_model()
            
            if model is not None and hasattr(predictor, 'X_train') and hasattr(predictor, 'y_train'):
                # ì„±ëŠ¥ í‰ê°€
                train_score = model.score(predictor.X_train, predictor.y_train)
                test_score = model.score(predictor.X_test, predictor.y_test)
                
                # ì„±ëŠ¥ ì§€í‘œ í‘œì‹œ
                st.text("\n=== ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ===")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric(label="í•™ìŠµ ë°ì´í„° RÂ² ì ìˆ˜", value="{:.4f}".format(train_score))
                with col2:
                    st.metric(label="í…ŒìŠ¤íŠ¸ ë°ì´í„° RÂ² ìˆ˜ì¹˜", value="{:.4f}".format(test_score))
                
                # í•™ìŠµ ëª¨ë¸ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state['predictor'] = predictor
                st.session_state['model_trained'] = True
                
                st.success("ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ìƒˆë¡œìš´ ì…ì°°ê±´ì˜ ì‚¬ì •ë¥ ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                st.error("ëª¨ë¸ í•™ìŠµì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.session_state['model_trained'] = False
            
        except Exception as e:
            st.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.session_state['model_trained'] = False

# ì˜ˆì¸¡ ì‹¤í–‰ (ëª¨ë¸ì´ í•™ìŠµëœ ê²½ìš°ì—ë§Œ)
if st.session_state.get('model_trained', False):
    # ì˜ˆì¸¡í•  ë°ì´í„° ì„ íƒ
    prediction_candidates = processed_data[pd.isna(processed_data['1ìˆœìœ„ì‚¬ì •ë¥ '])].copy()
    prediction_data = prediction_candidates.dropna(subset=['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'íˆ¬ì°°ë¥ ', 'Aê°’', 'ìˆœê³µì‚¬ì›ê°€', 'ë°œì£¼ì²˜'])
    
    if len(prediction_data) > 0:
        st.subheader("ìƒˆë¡œìš´ ì…ì°°ê±´ ì •ë¥  ì˜ˆì¸¡ ê²°ê³¼")
        
        # ë°œì£¼ì²˜ ì¹´í…Œê³ ë¦¬ëŠ” ì›ë³¸ ë°ì´í„°ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        prediction_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'] = prediction_data['ë°œì£¼ì²˜'].apply(categorize_client)
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        # category_stats = show_category_statistics(processed_data)
        
        # ì˜ˆì¸¡ ë°ì´í„°ì— ì¹´í…Œê³ ë¦¬ë³„ ìˆœìœ„ ì •ë³´ ì¶”ê°€
        for i in range(1, 6):
            prediction_data[f'{i}ìˆœìœ„ êµ¬ê°„'] = prediction_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'].map(
                category_stats[f'{i}ìˆœìœ„ êµ¬ê°„']
            )
            prediction_data[f'{i}ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)'] = prediction_data['ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬'].map(
                category_stats[f'{i}ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)']
            )
        
        # ì˜ˆì¸¡ ì‹¤í–‰
        predictor = st.session_state['predictor']
        predictions = []
        
        for idx, row in prediction_data.iterrows():
            try:
                predicted_rate = predictor.predict_rate(row.to_dict())
                predictions.append(predicted_rate)
            except Exception as e:
                st.error(f"ì˜ˆì¸¡ ì˜¤ë¥˜ (ê³µê³ ë²ˆí˜¸: {row.get('ê³µê³ ë²ˆí˜¸', 'N/A')}): {str(e)}")
                predictions.append(np.nan)
        
        # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
        prediction_data['ì‚¬ì •ë¥ (MLì˜ˆì¸¡ê°’)'] = predictions
        
        # í‘œì‹œí•  ì—´ ì„ íƒ ë° ì •ë ¬
        display_columns = [
            'ê³µê³ ë²ˆí˜¸',
            'ê³µì‚¬ëª…',
            'ë°œì£¼ì²˜',
            'ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬',
            'ê¸°ì´ˆê¸ˆì•¡',
            'ì¶”ì •ê°€ê²©',
            'íˆ¬ì°°ë¥ ',
            'Aê°’',
            'ìˆœê³µì‚¬ì›ê°€',
            'ì‚¬ì •ë¥ (MLì˜ˆì¸¡ê°’)',
            '1ìˆœìœ„ êµ¬ê°„',
            '1ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)',
            '2ìˆœìœ„ êµ¬ê°„',
            '2ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)',
            '3ìˆœìœ„ êµ¬ê°„',
            '3ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)',
            '4ìˆœìœ„ êµ¬ê°„',
            '4ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)',
            '5ìˆœìœ„ êµ¬ê°„',
            '5ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)'
        ]
        
        # ì‹¤ì œ í‘œì‹œí•  ì—´ì€ ë°ì´í„°í”„ë ˆì„ì— ì¡´ì¬í•˜ëŠ” ì—´ë§Œ ì„ íƒ
        display_columns = [col for col in display_columns if col in prediction_data.columns]
        
        # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
        st.dataframe(
            prediction_data[display_columns].style.format({
                'ê³µê³ ë²ˆí˜¸': '{}',
                'ê³µì‚¬ëª…': '{}',
                'ë°œì£¼ì²˜': '{}',
                'ë°œì£¼ì²˜_ì¹´í…Œê³ ë¦¬': '{}',
                'ê¸°ì´ˆê¸ˆì•¡': '{:,.0f}',
                'ì¶”ì •ê°€ê²©': '{:,.0f}',
                'íˆ¬ì°°ë¥ ': '{:.4f}',
                'Aê°’': '{:.4f}',
                'ìˆœê³µì‚¬ì›ê°€': '{:,.0f}',
                'ì‚¬ì •ë¥ (MLì˜ˆì¸¡ê°’)': '{:.4f}',
                '1ìˆœìœ„ êµ¬ê°„': '{}',
                '2ìˆœìœ„ êµ¬ê°„': '{}',
                '3ìˆœìœ„ êµ¬ê°„': '{}',
                '4ìˆœìœ„ êµ¬ê°„': '{}',
                '5ìˆœìœ„ êµ¬ê°„': '{}',
                '1ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)': '{}',
                '2ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)': '{}',
                '3ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)': '{}',
                '4ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)': '{}',
                '5ìˆœìœ„ ì´ˆê³¼í™•ë¥ (%)': '{}'
            }),
            use_container_width=True
        )

else:
    st.info("ë¨¼ì € ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

